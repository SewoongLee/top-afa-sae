{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TR80GXY8S8dA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 5.,  4.,  3.],\n",
              "        [ 1.,  1.,  1.],\n",
              "        [ 1., 10.,  2.]])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "acts = torch.Tensor(\n",
        "    [[5,   4,   3],\n",
        "     [1,   1,   1],\n",
        "     [1,  10,   2],\n",
        "     ]\n",
        "    )\n",
        "self_W_dec = torch.Tensor(\n",
        "    [[1,2],\n",
        "     [3,4],\n",
        "     [5,6]]\n",
        "    )\n",
        "acts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_uWIB5BaXLnl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[32., 44.],\n",
              "        [ 9., 12.],\n",
              "        [41., 54.]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "no_act = acts @ self_W_dec # No activation; same shape with input x.\n",
        "no_act"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m8eIPpMauxkz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size, h = acts.shape\n",
        "batch_size, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cTkuV_v8XkSD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5.0000, 25.0000, 61.0000])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.norm(self_W_dec, p=2, dim=-1)**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vFIX9sPBXZeq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2.2361, 5.0000, 7.8102])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.norm(self_W_dec, p=2, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zOlN7YzxTTet"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If D (decoder) were unit vectors...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 125.0000,  400.0000,  549.0001],\n",
              "        [   5.0000,   25.0000,   61.0000],\n",
              "        [   5.0000, 2500.0000,  244.0000]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dec_scaled_acts = (acts * torch.norm(self_W_dec, p=2, dim=-1)).pow(2)\n",
        "print(\"If D (decoder) were unit vectors...\")\n",
        "dec_scaled_acts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JRovNM5GTYOK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 1, 0],\n",
              "        [2, 1, 0],\n",
              "        [1, 2, 0]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_indices = torch.argsort(dec_scaled_acts, dim=-1, descending=True)\n",
        "max_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sB4dFs2vTgEE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  549.0001,   949.0001, 10000.0000],\n",
              "        [   61.0000,    86.0000, 10000.0000],\n",
              "        [ 2500.0000,  2744.0000, 10000.0000]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cumulative_fa = torch.cumsum(torch.gather(dec_scaled_acts, -1, max_indices), dim=-1)\n",
        "cumulative_fa[..., -1] = 10000 # Ensure the last cumulative norm is large enough\n",
        "cumulative_fa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zE3IM5YLTzai"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2960.0002],\n",
              "        [ 225.0000],\n",
              "        [4596.9995]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# afa = 1\n",
        "# afa = 70\n",
        "# afa = 80\n",
        "# afa = 900\n",
        "# afa = 2000\n",
        "# afa = 2600\n",
        "# afa = 9999\n",
        "afa = torch.norm(no_act, p=2, dim=1, keepdim=True).pow(2)\n",
        "afa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "riKGNlbtAkjj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 23.4307,  30.8058, 100.0000],\n",
              "         [  7.8102,   9.2736, 100.0000],\n",
              "         [ 50.0000,  52.3832, 100.0000]]),\n",
              " tensor([[54.4059],\n",
              "         [15.0000],\n",
              "         [67.8012]]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cumulative_fa = torch.sqrt(cumulative_fa)\n",
        "afa = torch.sqrt(afa)\n",
        "cumulative_fa, afa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kzihhYZ-Tgu3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2, 2, 2])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Basic way: if exceed\n",
        "# print(cumulative_fa >= afa)\n",
        "# k = (cumulative_fa >= afa).int().argmax(dim=-1) + 1\n",
        "\n",
        "# Advance way: nearest index\n",
        "k = torch.abs(cumulative_fa - afa).argmin(dim=-1) + 1\n",
        "\n",
        "k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5uq3jOTYA9zL"
      },
      "outputs": [],
      "source": [
        "# k = torch.clamp(k, max=2)  # when using parameter k (but, this will converge to TopK)\n",
        "# k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q0ddu0wZqXfR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  4.,  3.],\n",
              "        [ 0.,  1.,  1.],\n",
              "        [ 0., 10.,  2.]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acts_topk = acts * torch.zeros_like(acts, dtype=torch.bool).scatter_(\n",
        "    dim=1,\n",
        "    index=max_indices,\n",
        "    src=torch.arange(acts.shape[1], device=acts.device).unsqueeze(0) < k.unsqueeze(1), # Mask of (batch_size, h); True for top-k positions\n",
        ")\n",
        "acts_topk\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
